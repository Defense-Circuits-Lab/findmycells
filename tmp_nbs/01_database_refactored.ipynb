{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# database_refactored\n",
    "\n",
    "> The database holds all the relevant metadata information related to the *findmycells* project and is used to keep track of the progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| default_exp database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProjectConfigs:\n",
    "    \n",
    "    def __init__(self, project_root_dir: Path, project_configs_filepath: Optional[Path]=None) -> None:\n",
    "        assert type(project_root_dir) == Path, '\"project_root_dir\" must be pathlib.Path referring to an existing directory.'\n",
    "        assert project_root_dir.is_dir(), '\"project_root_dir\" must be pathlib.Path referring to an existing directory.'\n",
    "        self.project_root_dir = project_root_dir\n",
    "        if type(project_configs_filepath) == Path:\n",
    "            self.attempt_loading_from_configs_filepath(project_configs_filepath = project_configs_filepath)\n",
    "        else:\n",
    "            self._initialize_project_in_root_dir()\n",
    "        \n",
    "\n",
    "    def attempt_loading_from_configs_filepath(self, project_configs_filepath: Path) -> None:\n",
    "        # prompt user to confirm before loading?\n",
    "        # load from yaml\n",
    "        # confirm that paths are all working --> make them all relative to root dir, such that only this would need to be changed!\n",
    "        # raise error if not successful\n",
    "        raise NotImplementedError('This shall enable resuming a previously started & mid-way saved '\n",
    "                                  'findmycells project. However, this is not yet implemted.')\n",
    "\n",
    "        \n",
    "    def _initialize_project_in_root_dir(self) -> None:\n",
    "        self._find_or_create_subdir_and_set_as_attr(attr_id = 'microscopy_images', keywords = ['microscopy', 'Microscopy'])\n",
    "        self._find_or_create_subdir_and_set_as_attr(attr_id = 'rois_to_analyze', keywords = ['rois', 'ROIs', 'ROIS', 'Rois'])\n",
    "        self._find_or_create_subdir_and_set_as_attr(attr_id = 'preprocessed_images', keywords = ['preprocessed', 'Preprocessed', 'pre-processed'])\n",
    "        self._find_or_create_subdir_and_set_as_attr(attr_id = 'segmentation_tool', keywords = ['tool', 'Tool'])\n",
    "        self._find_or_create_subdir_and_set_as_attr(attr_id = 'trained_models',\n",
    "                                                    keywords = ['models'],\n",
    "                                                    parent_dir = self.project_root_dir.joinpath(self.segmentation_tool_dir))\n",
    "        self._find_or_create_subdir_and_set_as_attr(attr_id = 'segmentation_tool_temp_dir',\n",
    "                                                    keywords = ['tmp', 'temp'],\n",
    "                                                    parent_dir = self.project_root_dir.joinpath(self.segmentation_tool_dir))\n",
    "        self._find_or_create_subdir_and_set_as_attr(attr_id = 'semantic_segmentations', keywords = ['semantic', 'Semantic'])\n",
    "        self._find_or_create_subdir_and_set_as_attr(attr_id = 'instance_segmentations', keywords = ['instance', 'Instance'])\n",
    "        self._find_or_create_subdir_and_set_as_attr(attr_id = 'postprocessed_images', keywords = ['postprocessed', 'Postprocessed', 'post-processed'])\n",
    "        self._find_or_create_subdir_and_set_as_attr(attr_id = 'quantified_segmentations', keywords = ['quantified', 'Quantified', 'quantification', 'Quantification'])\n",
    "        self._find_or_create_subdir_and_set_as_attr(attr_id = 'results', keywords = ['results', 'Results'])\n",
    "        self._find_or_create_subdir_and_set_as_attr(attr_id = 'inspection', keywords = ['inspect', 'Inspect'])\n",
    "        \n",
    "        \n",
    "    def _find_or_create_subdir_and_set_as_attr(self, attr_id: str, keywords: List[str], parent_dir: Path=self.project_root_dir) -> None:\n",
    "        subdir_found = False\n",
    "        for path in parent_dir.iterdir():\n",
    "            if path.is_dir():\n",
    "                for key in keywords:\n",
    "                    if key in path.name:\n",
    "                        subdir_found = True\n",
    "                        subdir_path = path\n",
    "                        break\n",
    "        if subdir_found == False:\n",
    "            subdir_path = parent_dir.joinpath(attr_id).mkdir()\n",
    "        setattr(self, f'{attr_id}_dir', subdir_path.name)\n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "    def _find_or_create_group_subdir_trees(self, subdir_tree_root_dir: Path, level_id: str) -> None:\n",
    "        subdir_tree = {}\n",
    "        subdir_paths = [elem for elem in subdir_tree_root_dir.iterdir() if elem.is_dir()]\n",
    "        if len(subdir_paths) > 0:\n",
    "            for path in subdir_paths:\n",
    "                subdir_tree[path.name] = path\n",
    "        else:\n",
    "            for representative_subdir_name in [f'{level_id[:-1]}_a', f'{level_id[:-1]}_b']:\n",
    "                path = subdir_tree_root_dir.joinpath(representative_subdir_name)\n",
    "                path.mk_dir()\n",
    "                subdir_tree[path.name] = path\n",
    "        setattr(self, level_id, subdir_tree)\n",
    "\n",
    "            \n",
    "    microscopy_images_dir = self.project_root_dir.joinpath(self.microscopy_images_dir)\n",
    "    rois_to_analyze_dir = self.project_root_dir.joinpath(self.rois_to_analyze_dir)            \n",
    "    self._find_or_create_image_and_roi_subdir_trees(subdir_tree_root_dir = microscopy_images_dir, level_id = 'main_groups')\n",
    "    self._find_or_create_image_and_roi_subdir_trees(subdir_tree_root_dir = microscopy_images_dir, level_id = 'sub_groups')\n",
    "    self._find_or_create_image_and_roi_subdir_trees(subdir_tree_root_dir = microscopy_images_dir, level_id = 'subjects')\n",
    "    self._find_or_create_image_and_roi_subdir_trees(subdir_tree_root_dir = microscopy_images_dir, level_id = 'hemispheres')\n",
    "        \n",
    "        \n",
    "    def set_processing_type_specific_configs(self, \n",
    "                                             processing_object_class: ProcessingObject, \n",
    "                                             processing_type_specific_configs: Optional[Dict]\n",
    "                                            ) -> Dict:\n",
    "        processing_object = processing_object_class()\n",
    "        processing_type = processing_object.processing_type\n",
    "        default_values = processing_object.default_configs.values\n",
    "        valid_types = processing_object.default_configs.valid_types\n",
    "        if type(processing_type_specific_configs) == dict:\n",
    "            self._set_configs(attr_id = 'processing_configs',\n",
    "                              configs_key = processing_type,\n",
    "                              configs = processing_type_specific_configs,\n",
    "                              overwrite = True,\n",
    "                              valid_types = valid_types)\n",
    "        self._set_configs(attr_id = 'processing_configs',\n",
    "                          configs_key = processing_type,\n",
    "                          configs = default_values,\n",
    "                          overwrite = False,\n",
    "                          valid_types = valid_types)\n",
    "        return self.processing_configs[processing_type]\n",
    "        \n",
    "        \n",
    "    def set_strategy_specific_configs(self, \n",
    "                                      strategy: ProcessingStrategy, \n",
    "                                      strategy_configs: Optional[Dict] \n",
    "                                     ) -> Dict:\n",
    "        strategy_obj = strategy()\n",
    "        processing_type = strategy_obj.processing_type\n",
    "        default_values = strategy_obj.default_configs.values\n",
    "        valid_types = strategy_obj.default_configs.valid_types\n",
    "        if type(strategy_configs) == dict:\n",
    "            self._set_configs(attr_id = f'{processing_type}_strategy_configs',\n",
    "                              configs_key = strategy_obj.strategy_name,\n",
    "                              configs = strategy_configs,\n",
    "                              overwrite = True,\n",
    "                              valid_types = valid_types)\n",
    "        self._set_configs(attr_id = f'{processing_type}_strategy_configs',\n",
    "                          configs_key = strategy_obj.strategy_name,\n",
    "                          configs = default_values,\n",
    "                          overwrite = False,\n",
    "                          valid_types = valid_types)\n",
    "        all_strategy_configs = getattr(self, f'{processing_type}_strategy_configs')\n",
    "        return all_strategy_configs[strategy_obj.strategy_name]\n",
    "    \n",
    "    \n",
    "    def _set_configs(self, attr_id: str, configs_key: str, configs: Dict, overwrite: bool, valid_types: Optional[Dict[str, List[type]]]) -> None:\n",
    "        if hasattr(self, attr_id) == False:\n",
    "            setattr(self, attr_id, {})\n",
    "        existing_configs_dict_attr = getattr(self, attr_id)\n",
    "        if configs_key not in existing_configs_dict_attr.keys():\n",
    "            existing_configs_dict_attr[configs_key] = configs\n",
    "        else:\n",
    "            existing_configs = existing_configs_dict_attr[configs_key]\n",
    "            if overwrite == True:\n",
    "                for key, value in configs.items():\n",
    "                    existing_configs[key] = value\n",
    "            else:\n",
    "                for key, value in configs.items():\n",
    "                    if key not in existing_configs.keys():\n",
    "                        existing_configs[key] = value\n",
    "            existing_configs_dict_attr[configs_key] = existing_configs\n",
    "        updated_configs = existing_configs_dict_attr[configs_key]\n",
    "        if type(valid_types) == dict:\n",
    "            for key, value in updated_configs:\n",
    "                assert type(value) in valid_types[key], f'The configs value you passed as \"{key}\" (= {value}) is not of the required type: {valid_types[key]}.'\n",
    "        setattr(self, attr_id, existing_configs_dict_attr)\n",
    "        \n",
    "        \n",
    "    def export_as_yml(self) -> None:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Database:\n",
    "\n",
    "    def __init__(self, project_configs: ProjectConfigs) -> None:\n",
    "        self.project_configs = project_configs\n",
    "        self.update_file_infos()\n",
    "        \n",
    "        \n",
    "    def update_file_infos(self) -> None:\n",
    "        if hasattr(self, 'file_infos') == False:\n",
    "            self.file_infos = {'file_id': [],\n",
    "                               'original_filename': [],\n",
    "                               'main_group_id': [],\n",
    "                               'subgroup_id': [],\n",
    "                               'subject_id': [],\n",
    "                               'hemisphere_id': [],\n",
    "                               'microscopy_filepath': [],\n",
    "                               'microscopy_filetype': [],\n",
    "                               'rois_present': [],\n",
    "                               'rois_filepath': [],\n",
    "                               'rois_filetype': []}\n",
    "        if len(self.file_infos['file_id']) > 0:\n",
    "            file_id = max([int(file_id_str) for file_id_str in self.file_infos['file_id']]) + 1\n",
    "        else:\n",
    "            file_id = 0\n",
    "        microscopy_images_dir = self.project_configs.project_root_dir.joinpath(self.project_configs.microscopy_images_dir)\n",
    "        rois_to_analyze_dir = self.project_configs.project_root_dir.joinpath(self.project_configs.rois_to_analyze_dir)\n",
    "        for main_group_id_subdir_path in utils.list_dir_no_hidden(path = microscopy_images_dir, only_dirs = True):\n",
    "            for subgroup_id_subdir_path in utils.list_dir_no_hidden(path = main_group_id_subdir_path, only_dirs = True):\n",
    "                for subject_id_subdir_path in utils.list_dir_no_hidden(path = subgroup_id_subdir_path, only_dirs = True):\n",
    "                    for hemisphere_id_subdir_path in utils.list_dir_no_hidden(path = subject_id_subdir_path, only_dirs = True):\n",
    "                        for filepath in utils.list_dir_no_hidden(path = hemisphere_id_subdir_path, only_files = True):\n",
    "                            self.file_infos['file_id'].append(str(file_id).zfill(4))\n",
    "                            original_filename = filepath.name[:filepath.name.find('.')]\n",
    "                            self.file_infos['original_filename'].append(original_filename)\n",
    "                            self.file_infos['main_group_id'].append(main_group_id_subdir_path.name)\n",
    "                            self.file_infos['subgroup_id'].append(subgroup_id_subdir_path.name)\n",
    "                            self.file_infos['subject_id'].append(subject_id_subdir_path.name)\n",
    "                            self.file_infos['hemisphere_id'].append(hemisphere_id_subdir_path.name)\n",
    "                            self.file_infos['microscopy_filepath'].append(filepath)\n",
    "                            self.file_infos['microscopy_filetype'].append(filepath.name[filepath.find('.'):])\n",
    "                            corresponding_dir_in_rois_to_analyze_dir = rois_to_analyze.joinpath(main_group_id_subdir_path.name,\n",
    "                                                                                                subgroup_id_subdir_path.name,\n",
    "                                                                                                subject_id_subdir_path.name,\n",
    "                                                                                                hemisphere_id_subdir_path.name)\n",
    "                            matching_roi_filepaths = []\n",
    "                            for roi_filepath in utils.list_dir_no_hidden(path = corresponding_dir_in_rois_to_analyze_dir, only_files = True):\n",
    "                                if roi_filepath.name[:roi_filepath.name.find('.')] == original_filename:\n",
    "                                    matching_roi_filepaths.append(matching_roi_filepaths)\n",
    "                            if len(matching_roi_filepaths) == 0:\n",
    "                                self.file_infos['rois_present'].append(False)\n",
    "                                self.file_infos['rois_filepath'].append('not_available')\n",
    "                                self.file_infos['rois_filetype'].append('not_available')\n",
    "                            elif len(matching_roi_filepaths) == 1:\n",
    "                                self.file_infos['rois_present'].append(True)\n",
    "                                self.file_infos['rois_filepath'].append(matching_roi_filepaths[0])\n",
    "                                self.file_infos['rois_filetype'].append(matching_roi_filepaths[0].name[matching_roi_filepaths[0].name.find('.'):])\n",
    "                            else:\n",
    "                                raise ValueError('It seems like you provided more than a single ROI file in '\n",
    "                                                 f'{corresponding_dir_in_rois_to_analyze_dir} that matches the microscopy '\n",
    "                                                 f'image filename: {original_filename}. If you want to quantify image features '\n",
    "                                                 'within multiple ROIs per image, please use RoiSets created with ImageJ as '\n",
    "                                                 'described here: [Documentation link not provided yet - please raise an issue on '\n",
    "                                                 'https://github.com/Defense-Circuits-Lab/findmycells - thank you!')\n",
    "                            file_id += 1\n",
    "                            \n",
    "\n",
    "    def get_file_infos(self, identifier: str) -> Dict:\n",
    "        # supports use of either original_filename, file_id, or microscopy_filepath as input parameter identifier       \n",
    "        if identifier in self.file_infos['file_id']:\n",
    "            index = self.file_infos['file_id'].index(identifier)\n",
    "        elif identifier in self.file_infos['original_filename']:\n",
    "            index = self.file_infos['original_filename'].index(identifier)\n",
    "        elif identifier in self.file_infos['microscopy_filepath']:\n",
    "            index = self.file_infos['microscopy_filepath'].index(identifier)\n",
    "        else:\n",
    "            raise ValueError(f'{identifier} is not a valid input!')\n",
    "        file_infos = {}    \n",
    "        for key, list_of_values in self.file_infos.items():\n",
    "            if len(list_of_values) > 0:\n",
    "                file_infos[key] = list_of_values[index]\n",
    "        return file_infos\n",
    "    \n",
    "    \n",
    "    def add_new_key_to_file_infos(self, key: str, values: Optional[List]=None, preferred_empty_value: Union[bool, str, None]=None) -> None:\n",
    "        \"\"\"\n",
    "        Allows us to add a new key-value-pair to the file_infos dict\n",
    "        If values is not passed, a list full of 'preferred_empty_value' that matches the length of file_ids will be created\n",
    "        If values is passed, it has to be a list of the length of file_id\n",
    "        \"\"\"\n",
    "        assert key not in self.file_infos.keys(), f'The key (= {key}) you are trying to add to file_infos is already in file_infos.'\n",
    "        assert type(values) in [list, type(None)], '\"values\" has to be either None or a list of values that matches the length of file_infos[\"file_id\"].'\n",
    "        length = len(self.file_infos['file_id'])\n",
    "        if values == None:\n",
    "            values = [preferred_empty_value] * length\n",
    "            self.file_infos[key] = values\n",
    "        else:\n",
    "            self.file_infos[key] = values\n",
    "        \n",
    "     \n",
    "    def update_file_infos(self, file_id: str, updates: Dict, preferred_empty_value: Union[bool, str, None]=None) -> None: \n",
    "        index = self.file_infos['file_id'].index(file_id)\n",
    "        for key, value in updates.items():\n",
    "            if key not in self.file_infos.keys():\n",
    "                self.add_new_key_to_file_infos(key, preferred_empty_value = preferred_empty_value)\n",
    "            self.file_infos[key][index] = value\n",
    "            \n",
    "    \n",
    "    def get_file_ids_to_process(self, input_file_ids: Optional[List], process_tracker_key: str, overwrite: bool) -> List:\n",
    "        if input_file_ids == None:\n",
    "            input_file_ids = self.file_infos['file_id']\n",
    "        if process_tracker_key not in self.file_infos.keys():\n",
    "            self.add_new_key_to_file_infos(process_tracker_key)\n",
    "        if overwrite == True:\n",
    "            output_file_ids = input_file_ids\n",
    "        else:\n",
    "            process_tracker_status = []\n",
    "            for file_id in input_file_ids:\n",
    "                index = self.file_infos['file_id'].index(file_id)\n",
    "                process_tracker_status.append(self.file_infos[process_tracker_key][index])\n",
    "            output_file_ids = [elem[0] for elem in zip(input_file_ids, process_tracker_status) if elem[1] == False or elem[1] == None]\n",
    "        return output_file_ids.copy()\n",
    "    \n",
    "    \n",
    "    def get_batches_of_file_ids(self, input_file_ids: Optional[List], batch_size: int) -> List[List[int]]:\n",
    "        if input_file_ids == None:\n",
    "            input_file_ids = self.file_infos['file_id']        \n",
    "        if len(input_file_ids) % batch_size == 0:\n",
    "            total_batches = int(len(input_file_ids) / batch_size)\n",
    "        else:\n",
    "            total_batches = int(len(input_file_ids) / batch_size) + 1\n",
    "        file_ids_per_batch = []\n",
    "        for batch in range(total_batches):\n",
    "            if len(input_file_ids) >= batch_size:\n",
    "                sampled_file_ids = random.sample(input_file_ids, batch_size)\n",
    "            else:\n",
    "                sampled_file_ids = input_file_ids.copy()\n",
    "            file_ids_per_batch.append(sampled_file_ids)\n",
    "            for file_id in sampled_file_ids:\n",
    "                input_file_ids.remove(file_id)\n",
    "        return file_ids_per_batch\n",
    "    \n",
    "    \n",
    "    def import_rois_dict(self, file_id: str, rois_dict: Dict[str, Dict[str, Polygon]]) -> None:\n",
    "        if hasattr(self, 'area_rois_for_quantification') == False:\n",
    "            self.area_rois_for_quantification = {}\n",
    "        self.area_rois_for_quantification[file_id] = rois_dict\n",
    "    \n",
    "\n",
    "    # continue here\n",
    "    def remove_file_id_from_project(self, file_id: str) -> None:\n",
    "        index = self.file_infos['file_id'].index(file_id)\n",
    "        original_file_id = self.file_infos['original_file_id'][index]\n",
    "        # Move all source files, i.e. microscopy image file and roi file(s):\n",
    "        subdirectories = utils.list_dir_no_hidden(self.project_root_dir)\n",
    "        self.check_and_create_remaining_directories(root_dir = self.project_root_dir,\n",
    "                                                    subdirectory_attributes = {'removed_files_dir': {'foldername': '08_removed_files', 'key_substring': 'removed_files'}})\n",
    "        for source_data_type in ['microscopy', 'rois']:\n",
    "            source_filepath = self.file_infos[f'{source_data_type}_filepath'][index]\n",
    "            if type(source_filepath) == list:\n",
    "                for filepath in source_filepath:\n",
    "                    shutil.move(filepath.as_posix(), self.removed_files_dir.as_posix())\n",
    "            else:\n",
    "                shutil.move(source_filepath.as_posix(), self.removed_files_dir.as_posix())\n",
    "        # Delete all files that were already generated from findmycells:\n",
    "        for directory in [self.preprocessed_images_dir, \n",
    "                          self.semantic_segmentations_dir, \n",
    "                          self.instance_segmentations_dir, \n",
    "                          self.inspected_area_plots_dir,\n",
    "                          self.inspection_final_label_planes_dir,\n",
    "                          self.inspection_planes_for_quantification]:\n",
    "            filenames = listdir_nohidden(directory)\n",
    "            for filename in filenames:\n",
    "                if filename.startswith(file_id):\n",
    "                    os.remove(directory.joinpath(filename).as_posix())\n",
    "        # Remove from file_infos:\n",
    "        for key in self.file_infos.keys():\n",
    "            self.file_infos[key].pop(index)\n",
    "        # Remove from area_rois_for_quantification:\n",
    "        if file_id in self.area_rois_for_quantification.keys():\n",
    "            self.area_rois_for_quantification.pop(file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import List, Dict, Optional, Union\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "#from .utils import listdir_nohidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# ToDo: improve how project directory is constructed & how filepaths are fetched\n",
    "MAIN_SUBDIR_ATTRIBUTES = {'preprocessed_images_dir': {'foldername': '02_preprocessed_images', 'key_substring': 'preprocessed'},\n",
    "                          'segmentation_tool_dir': {'foldername': '03a_segmentation_tool', 'key_substring': 'tool'},\n",
    "                          'semantic_segmentations_dir': {'foldername': '03b_semantic_segmentations', 'key_substring': 'semantic'},\n",
    "                          'instance_segmentations_dir': {'foldername': '03c_instance_segmentations', 'key_substring': 'instance'},\n",
    "                          'quantified_segmentations_dir': {'foldername': '04_quantified_segmentations', 'key_substring': 'quantified'},\n",
    "                          'results_dir': {'foldername': '05_results', 'key_substring': 'results'},\n",
    "                          'inspection_dir': {'foldername': '06_inspection', 'key_substring': 'inspection'}}\n",
    "\n",
    "SEGMENTATION_TOOL_SUBDIR_ATTRIBUTES = {'trained_models_dir': {'foldername': 'trained_models', 'key_substring': 'models'},\n",
    "                                       'segmentation_tool_temp_dir': {'foldername': 'temp', 'key_substring': 'temp'}}\n",
    "                                \n",
    "INSPECTION_SUBDIR_ATTRIBUTES = {'inspected_area_plots_dir': {'foldername': 'inspected_area_plots', 'key_substring': 'inspected_area'},\n",
    "                                'inspection_final_label_planes_dir': {'foldername': 'planes_with_final_label_ids', 'key_substring': 'final_label_ids'},\n",
    "                                'inspection_planes_for_quantification': {'foldername': 'planes_for_quantification', 'key_substring': 'for_quantification'}}\n",
    "\n",
    "RENAMING_DICT = {'file_id': 'File ID', \n",
    "                 'original_file_id': 'Original File ID',               \n",
    "                 'group_id': 'Group ID', \n",
    "                 'subject_id': 'Subject ID', \n",
    "                 'microscopy_filepath': 'Microscopy Filepath', \n",
    "                 'microscopy_filetype': 'Microscopy Filetype',\n",
    "                 'rois_present': 'Rois Present', \n",
    "                 'rois_filepath': 'Rois Filepath',\n",
    "                 'rois_filetype': 'Rois Filetype',\n",
    "                 'preprocessing_completed': 'Preprocessing Completed',\n",
    "                 'RGB': 'RGB',\n",
    "                 'total_image_planes': 'Total Image Planes',\n",
    "                 'cropping_method': 'Cropping Method',\n",
    "                 'cropping_row_indices': 'Cropping Row Indices',\n",
    "                 'cropping_column_indices': 'Cropping Column Indices',\n",
    "                 'quantification_completed': 'Quantification Completed'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# ToDo - return list of Path objects\n",
    "def listdir_nohidden(path: Path) -> List:\n",
    "    return [f for f in os.listdir(path) if f.startswith('.') == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# ToDo - split in subclasses?\n",
    "\n",
    "class Database():\n",
    "    '''\n",
    "    The database object is intended to collect and hold all information about\n",
    "    the image analysis project at hand. Depending on the type of analysis that \n",
    "    shall be performed, the Database needs to be flexible and adopt to the \n",
    "    respective needs. For instance, there might be more than just two groups \n",
    "    that are investigated, or just a single group but with multiple images per \n",
    "    subject, and so on.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, user_input_via_gui: dict) -> None:\n",
    "        self.extract_user_input(user_input_via_gui)\n",
    "        self.construct_main_subdirectories()\n",
    "        if hasattr(self, 'only_duplication') == False:\n",
    "            self.create_file_infos()\n",
    "        elif self.only_duplication == False:\n",
    "            self.create_file_infos()\n",
    "        else:\n",
    "            self.load_all()\n",
    "\n",
    "        \n",
    "    \n",
    "    def extract_user_input(self, user_input: dict) -> None:\n",
    "        for key, value in user_input.items():\n",
    "            if hasattr(self, key) == False:\n",
    "                setattr(self, key, value)\n",
    "\n",
    "    \n",
    "                      \n",
    "    \n",
    "    \n",
    "    def create_file_infos(self) -> None:\n",
    "        # Initial information will be retrieved from the microscopy_image_dir\n",
    "        self.file_infos = {'file_id': list(),\n",
    "                           'original_file_id': list(),\n",
    "                           'group_id': list(),\n",
    "                           'subject_id': list(),\n",
    "                           'microscopy_filepath': list(),\n",
    "                           'microscopy_filetype': list(),\n",
    "                           'rois_present': list(),\n",
    "                           'rois_filepath': list(),\n",
    "                           'rois_filetype': list()}\n",
    "        file_id = 0\n",
    "        for group in listdir_nohidden(self.microscopy_image_dir):\n",
    "            for subject in listdir_nohidden(self.microscopy_image_dir.joinpath(group)):\n",
    "                for filename in listdir_nohidden(self.microscopy_image_dir.joinpath(group, subject)):\n",
    "                    self.file_infos['file_id'].append(str(file_id).zfill(4))\n",
    "                    original_file_id = filename[:filename.find('.')]\n",
    "                    self.file_infos['original_file_id'].append(original_file_id)\n",
    "                    self.file_infos['group_id'].append(group)\n",
    "                    self.file_infos['subject_id'].append(subject)\n",
    "                    self.file_infos['microscopy_filepath'].append(self.microscopy_image_dir.joinpath(group, subject, filename))\n",
    "                    self.file_infos['microscopy_filetype'].append(filename[filename.find('.'):])\n",
    "                    \n",
    "                    matching_roi_filenames = [elem for elem in listdir_nohidden(self.rois_to_analyze_dir.joinpath(group,subject)) if elem.startswith(original_file_id)]\n",
    "                    if len(matching_roi_filenames) == 0:\n",
    "                        self.file_infos['rois_present'].append(False)\n",
    "                        self.file_infos['rois_filepath'].append('not_available')\n",
    "                        self.file_infos['rois_filetype'].append('not_available')                      \n",
    "                    elif len(matching_roi_filenames) == 1:\n",
    "                        roi_filename = matching_roi_filenames[0]\n",
    "                        self.file_infos['rois_present'].append(True)\n",
    "                        self.file_infos['rois_filepath'].append(self.rois_to_analyze_dir.joinpath(group, subject, roi_filename))\n",
    "                        self.file_infos['rois_filetype'].append(roi_filename[roi_filename.find('.'):])\n",
    "                    else:\n",
    "                        message_line_0 = 'It seems like you provided more than a single ROI file in:\\n'\n",
    "                        message_line_1 = f'{self.rois_to_analyze_dir.joinpath(group,subject)}\\n'\n",
    "                        message_line_2 = 'If you want to quantify image features within multiple ROIs per image, please use RoiSets created with ImageJ as described here:\\n'\n",
    "                        message_line_3 = 'Documentation not live yet - please contact: segebarth_d@ukw.de for more information.'\n",
    "                        error_message = message_line_0 + message_line_1 + message_line_2 + message_line_3\n",
    "                        raise ValueError(error_message)\n",
    "                    \n",
    "                    file_id += 1\n",
    "                \n",
    "                    \n",
    "    def get_file_infos(self, identifier: str) -> Dict:\n",
    "        # supports use of either original_file_id, file_id, or microscopy_filepath as input parameter identifier       \n",
    "        if identifier in self.file_infos['file_id']:\n",
    "            index = self.file_infos['file_id'].index(identifier)\n",
    "        elif identifier in self.file_infos['original_file_id']:\n",
    "            index = self.file_infos['original_file_id'].index(identifier)\n",
    "        elif identifier in self.file_infos['microscopy_filepath']:\n",
    "            index = self.file_infos['microscopy_filepath'].index(identifier)\n",
    "        else:\n",
    "            raise NameError(f'{identifier} is not a valid input!')\n",
    "        \n",
    "        file_infos = dict()    \n",
    "        for key in self.file_infos.keys():\n",
    "            if len(self.file_infos[key]) > 0:\n",
    "                file_infos[key] = self.file_infos[key][index]\n",
    "         \n",
    "        return file_infos\n",
    "    \n",
    "    \n",
    "    def add_new_key_to_file_infos(self, key: str, values: Optional[List]=None, preferred_empty_value: Union[bool, str, None]=None) -> None:\n",
    "        \"\"\"\n",
    "        Allows us to add a new key-value-pair to the file_infos dict\n",
    "        If values is not passed, a list full of 'preferred_empty_value' that matches the length of file_ids will be created\n",
    "        If values is passed, it has to be a list of the length of file_id\n",
    "        \"\"\"\n",
    "        if key in self.file_infos.keys():\n",
    "            raise ValueError(\"The key you are trying to add is already in file_infos.\")\n",
    "        else:\n",
    "            length = len(self.file_infos['file_id'])\n",
    "            if values == None:\n",
    "                values = [preferred_empty_value] * length\n",
    "                self.file_infos[key] = values\n",
    "            elif type(values) != list:\n",
    "                raise TypeError(\"'values' has to be 'None' or a list that matches the length of file_infos['file_ids']\")\n",
    "            else:\n",
    "                if len(values) == length:\n",
    "                    self.file_infos[key] = values                \n",
    "                else:\n",
    "                    raise ValueError(\"The list of values that you provided does not match the length of file_infos['file_ids']!\")\n",
    "            \n",
    "\n",
    "    def update_file_infos(self, file_id: str, updates: Dict, preferred_empty_value: Union[bool, str, None]=None) -> None: \n",
    "        index = self.file_infos['file_id'].index(file_id)\n",
    "        for key, value in updates.items():\n",
    "            if key not in self.file_infos.keys():\n",
    "                self.add_new_key_to_file_infos(key, preferred_empty_value = preferred_empty_value)\n",
    "            self.file_infos[key][index] = value\n",
    "\n",
    "    \n",
    "    def get_file_ids_to_process(self, input_file_ids: Optional[List], process_tracker_key: str, overwrite: bool) -> List:\n",
    "        if input_file_ids == None:\n",
    "            input_file_ids = self.file_infos['file_id']\n",
    "        if process_tracker_key not in self.file_infos.keys():\n",
    "            self.add_new_key_to_file_infos(process_tracker_key)\n",
    "        if overwrite:\n",
    "            output_file_ids = input_file_ids\n",
    "        else:\n",
    "            process_tracker_status = list()\n",
    "            for file_id in input_file_ids:\n",
    "                index = self.file_infos['file_id'].index(file_id)\n",
    "                process_tracker_status.append(self.file_infos[process_tracker_key][index])\n",
    "            output_file_ids = [elem[0] for elem in zip(input_file_ids, process_tracker_status) if elem[1] == False or elem[1] == None]\n",
    "        return output_file_ids.copy()\n",
    "\n",
    "\n",
    "    def get_batches_of_file_ids(self, input_file_ids: Optional[List], batch_size: int) -> List[List[int]]:\n",
    "        if input_file_ids == None:\n",
    "            input_file_ids = self.file_infos['file_id']        \n",
    "        if len(input_file_ids) % batch_size == 0:\n",
    "            total_batches = int(len(input_file_ids) / batch_size)\n",
    "        else:\n",
    "            total_batches = int(len(input_file_ids) / batch_size) + 1\n",
    "        file_ids_per_batch = list()\n",
    "        for batch in range(total_batches):\n",
    "            if len(input_file_ids) >= batch_size:\n",
    "                sampled_file_ids = random.sample(input_file_ids, batch_size)\n",
    "            else:\n",
    "                sampled_file_ids = input_file_ids.copy()\n",
    "            file_ids_per_batch.append(sampled_file_ids)\n",
    "            for file_id in sampled_file_ids:\n",
    "                input_file_ids.remove(file_id)\n",
    "        return file_ids_per_batch\n",
    "    \n",
    "    \n",
    "    def import_rois_dict(self, file_id: str, rois_dict: Dict) -> None:\n",
    "        if hasattr(self, 'area_rois_for_quantification') == False:\n",
    "            self.area_rois_for_quantification = dict()\n",
    "        self.area_rois_for_quantification[file_id] = rois_dict\n",
    "        \n",
    "    # Continue here\n",
    "    def remove_file_id_from_project(self, file_id: str) -> None:\n",
    "        index = self.file_infos['file_id'].index(file_id)\n",
    "        original_file_id = self.file_infos['original_file_id'][index]\n",
    "        # Move all source files, i.e. microscopy image file and roi file(s):\n",
    "        subdirectories = listdir_nohidden(self.project_root_dir)\n",
    "        self.check_and_create_remaining_directories(root_dir = self.project_root_dir,\n",
    "                                                    subdirectory_attributes = {'removed_files_dir': {'foldername': '08_removed_files', 'key_substring': 'removed_files'}})\n",
    "        for source_data_type in ['microscopy', 'rois']:\n",
    "            source_filepath = self.file_infos[f'{source_data_type}_filepath'][index]\n",
    "            if type(source_filepath) == list:\n",
    "                for filepath in source_filepath:\n",
    "                    shutil.move(filepath.as_posix(), self.removed_files_dir.as_posix())\n",
    "            else:\n",
    "                shutil.move(source_filepath.as_posix(), self.removed_files_dir.as_posix())\n",
    "        # Delete all files that were already generated from findmycells:\n",
    "        for directory in [self.preprocessed_images_dir, \n",
    "                          self.semantic_segmentations_dir, \n",
    "                          self.instance_segmentations_dir, \n",
    "                          self.inspected_area_plots_dir,\n",
    "                          self.inspection_final_label_planes_dir,\n",
    "                          self.inspection_planes_for_quantification]:\n",
    "            filenames = listdir_nohidden(directory)\n",
    "            for filename in filenames:\n",
    "                if filename.startswith(file_id):\n",
    "                    os.remove(directory.joinpath(filename).as_posix())\n",
    "        # Remove from file_infos:\n",
    "        for key in self.file_infos.keys():\n",
    "            self.file_infos[key].pop(index)\n",
    "        # Remove from area_rois_for_quantification:\n",
    "        if file_id in self.area_rois_for_quantification.keys():\n",
    "            self.area_rois_for_quantification.pop(file_id)\n",
    "    \n",
    "    \n",
    "    def save_all(self) -> None:\n",
    "        self.save_csv()\n",
    "        self.save_file_infos()\n",
    "        self.save_project_configs()\n",
    "    \n",
    "    \n",
    "    def save_csv(self) -> None:\n",
    "        df = pd.DataFrame(self.file_infos)\n",
    "        current_columns = list(df.columns)\n",
    "        new_columns = list()\n",
    "        for column_name in current_columns:\n",
    "            if column_name in RENAMING_DICT.keys():\n",
    "                new_columns.append(RENAMING_DICT[column_name])\n",
    "            else: \n",
    "                #print(f\"Warning: {column_name} not yet specified in renaming dictionary\")\n",
    "                new_columns.append(column_name)\n",
    "        df.columns=new_columns\n",
    "        df.to_csv(self.results_dir.joinpath(f'{datetime.now().strftime(\"%Y_%m_%d\")}_findmycells_overview_for_user.csv').as_posix())\n",
    "    \n",
    "    \n",
    "    def save_file_infos(self) -> None:\n",
    "        filepath = self.results_dir.joinpath(f'{datetime.now().strftime(\"%Y_%m_%d\")}_findmycells_project_summary.p').as_posix()\n",
    "        with open(filepath, 'wb') as io:\n",
    "            pickle.dump(self.file_infos, io)\n",
    "            \n",
    "        \n",
    "    def save_project_configs(self) -> None:\n",
    "        project_configs = self.__dict__.copy()\n",
    "        if 'file_infos' in project_configs.keys():\n",
    "            project_configs.pop('file_infos')\n",
    "        if 'only_duplication' in project_configs.keys():\n",
    "            project_configs.pop('only_duplication')  \n",
    "            \n",
    "        filepath = self.results_dir.joinpath(f'{datetime.now().strftime(\"%Y_%m_%d\")}_findmycells_project_configs.p').as_posix()       \n",
    "        with open(filepath, 'wb') as io:\n",
    "            pickle.dump(project_configs, io)\n",
    "    \n",
    "    \n",
    "    def load_all(self) -> None:\n",
    "        result_files = [fname for fname in listdir_nohidden(self.results_dir) if fname.endswith('.p')]\n",
    "        result_files.sort(reverse = True)\n",
    "        if len(result_files) < 2:\n",
    "            raise FileNotFoundError(f\"CouldnÂ´t find the required files in {self.results_dir.as_posix()}\")\n",
    "        \n",
    "        else:\n",
    "            project_summary_filename = [fname for fname in result_files if fname.endswith('project_summary.p')][0]\n",
    "            with open(self.results_dir.joinpath(project_summary_filename).as_posix(), 'rb') as io:\n",
    "                self.file_infos = pickle.load(io)\n",
    "\n",
    "            project_configs_filename = [fname for fname in result_files if fname.endswith('project_configs.p')][0]\n",
    "            with open(self.results_dir.joinpath(project_configs_filename).as_posix(), 'rb') as io:\n",
    "                project_configs = pickle.load(io)\n",
    "            \n",
    "            for key, value in project_configs.items():\n",
    "                if hasattr(self, key) == False:\n",
    "                    setattr(self, key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
